\section{Results and Discussion}

Quantitative evaluation in terms of MOTA, IDF1, and HOTA reveals that the OpenCV-based model attains competitive detection quality in scenes with moderate background dynamics and limited occlusion, achieving reasonable IoU and tracking metrics. However, performance degrades significantly in dense flocks, rapid camera motion, and heavily cluttered backgrounds. In contrast, NetTrack exhibits consistently higher tracking accuracy across all metrics, particularly in challenging scenarios with severe occlusion and dense motion. These results corroborate the hypotheses regarding the strengths and limitations of classical motion cues versus learned representations.

The results confirm that deep-learning-based trackers are more robust in highly dynamic environments, while the proposed OpenCV-based model achieves reasonable performance with significantly lower computational cost, directly addressing the research questions posed in the introduction.